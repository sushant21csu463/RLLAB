{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "72vQGjvSR4AI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9SLu3gaNSjga"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "print(gpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAepNfke6Eau",
        "outputId": "320630e1-bc2d-46cf-d9cf-6d114017dbb0"
      },
      "outputs": [],
      "source": [
        "# drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0sQiVzy-025"
      },
      "outputs": [],
      "source": [
        "# data_dir = '/content/drive/My Drive/Data'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q72UUSLZi6ip",
        "outputId": "55400d2a-2e6d-4311-9108-ffa12da9df70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['HAM10000_images_part_2', 'HAM10000_images_part_1', 'HAM10000_images', 'HAM']"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# os.listdir(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "a36WMtVCpivm"
      },
      "outputs": [],
      "source": [
        "# import cv2\n",
        "import imghdr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "tc2hteLMp7Qz"
      },
      "outputs": [],
      "source": [
        "img_exts=['jpg','jpeg','png','bmp']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yQ_XlFfi9n_"
      },
      "outputs": [],
      "source": [
        "# for image_class in os.listdir(data_dir):\n",
        "#   for image in os.listdir(os.path.join(data_dir, image_class)):\n",
        "#     image_path = os.path.join(data_dir,image_class, image)\n",
        "#     try:\n",
        "#       img = cv2.imread(image_path)\n",
        "#       tip = imghdr.what(image_path)\n",
        "#       if tip not in img_exts:\n",
        "#         print('Image not in ext list {}'.format(image_path))\n",
        "#         os.remove(image_path)\n",
        "#     except Exception as e:\n",
        "#       print('Issue with image {}'.format(image_path))\n",
        "#       os.remove(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jG8ywu0H8DPh"
      },
      "outputs": [],
      "source": [
        "# tf.data.Dataset??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KKSqVDJa_Wya"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib  import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "38W0yRzxcTvm"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from keras import optimizers\n",
        "from keras.applications import MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "EbD6DMthhcRj"
      },
      "outputs": [],
      "source": [
        "base_model = MobileNetV2(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))\n",
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Conv2D(no_of_filters, size_of_filters, stride)\n",
        "\n",
        "model.add(base_model)\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.40))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.40))\n",
        "model.add(Dense(7, activation='sigmoid'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "qO_SkcT9iTWI"
      },
      "outputs": [],
      "source": [
        "# # Conv2D(no_of_filters, size_of_filters, stride)\n",
        "\n",
        "# model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))\n",
        "# model.add(MaxPooling2D())\n",
        "\n",
        "# model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
        "# model.add(MaxPooling2D())\n",
        "\n",
        "# model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
        "# model.add(MaxPooling2D())\n",
        "\n",
        "# model.add(Flatten())\n",
        "\n",
        "# model.add(Dense(256, activation='relu'))\n",
        "# model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "xqW3v89MgAt6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "r5aRbDcCeu2E"
      },
      "outputs": [],
      "source": [
        "label_path = './HAM10000_metadata.csv'\n",
        "label_data = pd.read_csv(label_path)\n",
        "label_data['image_full_name'] = label_data['image_id'] + '.jpg'\n",
        "X = label_data[['image_full_name','dx','lesion_id']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "yygai3gKnqIT"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "Y = X.pop('dx').to_frame()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "-PnffjDToxAM"
      },
      "outputs": [],
      "source": [
        "train = pd.concat([X_train, y_train],axis=1)\n",
        "# val = pd.concat([X_val, y_val],axis=1)\n",
        "test = pd.concat([X_test, y_test],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "y-v0HqggRYXd"
      },
      "outputs": [],
      "source": [
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# encoder = LabelEncoder()\n",
        "# encoder.fit(val['dx'])\n",
        "# name_as_indexes_test = encoder.transform(val['dx'])\n",
        "# val['label'] = name_as_indexes_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "P1G8mp1fu5S7"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(test['dx'])\n",
        "name_as_indexes_test = encoder.transform(test['dx'])\n",
        "test['label'] = name_as_indexes_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "7j1076GIWq1M"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_generator = ImageDataGenerator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "GZKuCURo2yxo",
        "outputId": "7528f9d6-e46b-4674-a859-68a9dea18717"
      },
      "outputs": [],
      "source": [
        "# data = tf.keras.utils.image_dataset_from_directory('./HAM10000_images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "OZX1U9ZE1gt3"
      },
      "outputs": [],
      "source": [
        "model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import sys\n",
        "# from PIL import Image\n",
        "# # sys.modules['Image'] = Image "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 5, 5, 64)          737344    \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 2, 2, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2, 2, 64)          0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 7)                 903       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,029,127\n",
            "Trainable params: 2,995,015\n",
            "Non-trainable params: 34,112\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PUsTja0lna5G",
        "outputId": "a4dd5b8e-77f7-4c9b-8966-614d1016e981"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8012 validated image filenames belonging to 7 classes.\n",
            "Found 2003 validated image filenames belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "img_size=(224,224)\n",
        "gen=ImageDataGenerator(rescale=1/255,rotation_range= 10, zoom_range=0.1, width_shift_range=0.0, height_shift_range=0.0)\n",
        "\n",
        "train_gen=gen.flow_from_dataframe(train, directory='./HAM10000_images/', x_col='image_full_name', y_col='dx', shuffle=True,\n",
        "                                 target_size=img_size, class_mode='categorical', batch_size=32, subset='training')\n",
        "# valid_gen=gen.flow_from_dataframe(val, directory='./HAM10000_images/', x_col='image_full_name', y_col='dx', shuffle=True,\n",
        "#                                  target_size=img_size, class_mode='categorical', batch_size=32, subset='validation')\n",
        "test_gen=gen.flow_from_dataframe(test, directory='./HAM10000_images/', x_col='image_full_name', y_col='dx', shuffle=False,\n",
        "                                 target_size=img_size, class_mode='categorical', batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "251/251 [==============================] - 133s 504ms/step - loss: 0.2493 - accuracy: 0.6781\n",
            "Epoch 2/10\n",
            "251/251 [==============================] - 110s 438ms/step - loss: 0.1826 - accuracy: 0.7421\n",
            "Epoch 3/10\n",
            "251/251 [==============================] - 107s 425ms/step - loss: 0.1631 - accuracy: 0.7692\n",
            "Epoch 4/10\n",
            "251/251 [==============================] - 114s 455ms/step - loss: 0.1712 - accuracy: 0.7650\n",
            "Epoch 5/10\n",
            "251/251 [==============================] - 102s 406ms/step - loss: 0.1520 - accuracy: 0.7822\n",
            "Epoch 6/10\n",
            "251/251 [==============================] - 113s 450ms/step - loss: 0.1430 - accuracy: 0.7981\n",
            "Epoch 7/10\n",
            "251/251 [==============================] - 101s 400ms/step - loss: 0.1388 - accuracy: 0.8103\n",
            "Epoch 8/10\n",
            "251/251 [==============================] - 102s 406ms/step - loss: 0.1579 - accuracy: 0.7812\n",
            "Epoch 9/10\n",
            "251/251 [==============================] - 105s 419ms/step - loss: 0.1403 - accuracy: 0.8037\n",
            "Epoch 10/10\n",
            "251/251 [==============================] - 103s 410ms/step - loss: 0.1469 - accuracy: 0.7996\n"
          ]
        }
      ],
      "source": [
        "history=model.fit(train_gen, verbose=1, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 33s 505ms/step - loss: 0.4000 - accuracy: 0.6680\n",
            "66.79980158805847\n"
          ]
        }
      ],
      "source": [
        "acc=model.evaluate(test_gen)[1]* 100\n",
        "print (acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(\"model_skin.h5\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
